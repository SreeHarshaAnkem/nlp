{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T16:52:37.433531Z",
     "start_time": "2021-10-06T16:52:37.338785Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guYzuv_Hdq0J",
    "outputId": "23575d1c-a254-47f2-cc0e-f1d59f4135f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cpu :(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.optim import Adam\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"running on gpu!!!\")\n",
    "else:\n",
    "    print(\"cpu :(\")\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "        print(\"running on colab\")\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        import sys\n",
    "        sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/ag_news\")\n",
    "\n",
    "from utils import ModelJob, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T16:52:37.981172Z",
     "start_time": "2021-10-06T16:52:37.835269Z"
    },
    "id": "3nw67DCUd04_"
   },
   "outputs": [],
   "source": [
    "class AgNewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, \n",
    "                vocab_size, min_frequency, \n",
    "                mode=\"train\", vocab=None):\n",
    "        super(AgNewsDataset).__init__()\n",
    "        logging.info(\"reading dataframe\")\n",
    "        self.df = df\n",
    "        self.nlp = spacy.load(name=\"en_core_web_sm\")\n",
    "        self.vocab_size = vocab_size\n",
    "        self.min_frequency = min_frequency\n",
    "        logging.info(f\"mode: {mode}\")\n",
    "        if mode == \"train\":\n",
    "            logging.info(\"preprocessing dataframe\")\n",
    "            self.preprocess_df()\n",
    "            logging.info(\"creating vocabulary\")\n",
    "            self.vocab = self.build_vocab()\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "            self.preprocess_df()\n",
    "            logging.info(\"preprocessing dataframe\")\n",
    "        logging.info(\"converting tokens to index\")\n",
    "        self.df[\"text_idx\"] = self.df[\"processed\"].apply(lambda ts: [self.vocab.get(t, self.vocab_size) \n",
    "                                                                                     for t in ts])\n",
    "        self.df[\"len\"] = self.df[\"text_idx\"].apply(len)\n",
    "    def preprocess_df(self):\n",
    "        self.df.columns = map(lambda x: x.lower(), self.df.columns)\n",
    "        self.df[\"text\"] = self.df[\"title\"] + \" \" + self.df[\"description\"]\n",
    "        self.df[\"text\"] = self.df[\"text\"].str.lower()\n",
    "        self.df[\"processed\"] = self.df[\"text\"].apply(self.preprocess)\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "        text = \" \".join(text.split())\n",
    "        doc = self.nlp(text, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\",\"ner\"])\n",
    "        lemmas = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        return lemmas\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        freq_dict = dict()\n",
    "        for index, row in self.df.iterrows():\n",
    "            for token in row[\"processed\"]:\n",
    "                freq_dict[token] = freq_dict.get(token, 0)+1\n",
    "        freq_dict = [(word, frequency) for word, frequency in freq_dict.items()\n",
    "                    if frequency >= self.min_frequency]\n",
    "        freq_dict = sorted(freq_dict, key = lambda x: x[1], reverse=True)\n",
    "        freq_dict = freq_dict[:self.vocab_size]\n",
    "        freq_dict = dict(freq_dict)\n",
    "        vocab = {token : idx+1 for idx, (token, _) in enumerate(freq_dict.items())}\n",
    "        return vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.iloc[idx][\"text_idx\"]\n",
    "        length = self.df.iloc[idx][\"len\"]\n",
    "        y = torch.tensor(self.df.iloc[idx][\"class index\"]-1)\n",
    "        return {\"X\": X,\n",
    "                \"lengths\": length,\n",
    "                \"y\": y}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X = [torch.tensor(row[\"X\"]) for row in batch]\n",
    "    lengths = [torch.tensor(row[\"lengths\"]) for row in batch]\n",
    "    y = [torch.tensor(row[\"y\"]) for row in batch]\n",
    "    X, y = pad_sequence(X, batch_first=True, padding_value=0), torch.tensor(y)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return X.to(device), lengths, y.to(device)\n",
    "    \n",
    "class NewsClassifierModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size,fc_units, num_classes):\n",
    "        super(NewsClassifierModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1,\n",
    "                                      embedding_dim=100, padding_idx=0)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim,\n",
    "                          hidden_size=hidden_size,\n",
    "                          bidirectional=True, \n",
    "                          batch_first=True)\n",
    "        self.attention = Attention(input_dim=2*hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(in_features=2*hidden_size, \n",
    "                           out_features=fc_units)\n",
    "        self.out = nn.Linear(in_features=fc_units,\n",
    "                            out_features=4)\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        (sequence, lengths) = x\n",
    "        \n",
    "        emb = self.embedding(sequence)\n",
    "        emb_packed = pack_padded_sequence(emb, lengths=lengths, \n",
    "                                          batch_first=True, enforce_sorted=False)\n",
    "        output, h_t = self.rnn(emb_packed)\n",
    "        output_padded, lengths_unpacked = pad_packed_sequence(output, batch_first=True, \n",
    "                                           padding_value=0)\n",
    "        mask = sequence!=0\n",
    "        context, attention_weights = self.attention((output_padded, mask))\n",
    "        hidden_states_dp = self.dropout(context)\n",
    "        fc_out = F.relu(self.fc(hidden_states_dp))\n",
    "        out = self.out(fc_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T16:55:46.226191Z",
     "start_time": "2021-10-06T16:52:37.985142Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVtHb2jbd4-e",
    "outputId": "ee26a454-f855-485a-b7e2-dbdcdd49c4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Read Dataframe\n",
      "INFO:root:Train Test Split\n",
      "INFO:root:Creating Datasets\n",
      "INFO:root:reading dataframe\n",
      "INFO:root:mode: train\n",
      "INFO:root:preprocessing dataframe\n",
      "INFO:root:creating vocabulary\n",
      "INFO:root:converting tokens to index\n",
      "INFO:root:reading dataframe\n",
      "INFO:root:mode: test\n",
      "INFO:root:preprocessing dataframe\n",
      "INFO:root:converting tokens to index\n",
      "INFO:root:Dataset lengths:: train: 37500, test: 12500\n",
      "INFO:root:Started Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.7667185068130493 : ACCURACY: 0.7014551758766174\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.5076186656951904 : ACCURACY: 0.8367968797683716\n",
      "Best epoch : 1\n",
      "Saving model : ag_news_classification_gru.pth at /content/drive/MyDrive/Colab Notebooks/ag_news\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/ag_news/ag_news_classification_gru.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ad2f01c816ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Started Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mmodel_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/nlp/classification/ag_news_classification/utils/utils.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/nlp/classification/ag_news_classification/utils/utils.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saving model : {self.model_save_name} at {self.model_save_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/ag_news/ag_news_classification_gru.pth'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        data_path = \"/content/drive/MyDrive/Colab Notebooks/ag_news\"\n",
    "        print(\"running on colab\")\n",
    "    else:\n",
    "        data_path = \"data/ag_news/\"\n",
    "        print(\"running on local\")\n",
    "    df = pd.read_csv(os.path.join(data_path,\"train.csv\"))\n",
    "    df = df.sample(n=50000, random_state=9)\n",
    "    logging.info(\"Read Dataframe\")\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df_train, df_test = train_test_split(df, stratify=df[\"Class Index\"], random_state=9)\n",
    "    df_train.shape, df_test.shape\n",
    "    logging.info(\"Train Test Split\")\n",
    "    \n",
    "    logging.info(\"Creating Datasets\")\n",
    "    train_ds = AgNewsDataset(df=df_train,\n",
    "                    vocab_size=1000, \n",
    "                    min_frequency=25, \n",
    "                    mode=\"train\", vocab=None)\n",
    "    test_ds = AgNewsDataset(df=df_test,\n",
    "            vocab_size=1000, \n",
    "            min_frequency=25, \n",
    "            mode=\"test\", vocab=train_ds.vocab)\n",
    "    logging.info(f\"Dataset lengths:: train: {len(train_ds)}, test: {len(test_ds)}\")\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "    test_dl = DataLoader(test_ds, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    model = NewsClassifierModel(vocab_size=1000, \n",
    "                      embedding_dim=100, \n",
    "                      hidden_size=128,\n",
    "                      fc_units=256,\n",
    "                      num_classes=4\n",
    "                     )\n",
    "    model = model.to(device)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(params=model.parameters(), lr=0.001)\n",
    "    \n",
    "    model_run =  ModelJob(model=model,\n",
    "                    dataloaders = {\"train\": train_dl, \"test\":test_dl},\n",
    "                    model_save_path = \"/content/drive/MyDrive/Colab Notebooks/ag_news\",\n",
    "                    model_save_name=\"ag_news_classification_gru.pth\",\n",
    "                    criterion=loss_func,\n",
    "                    optimizer=optimizer,\n",
    "                    n_epochs=10,\n",
    "                    phases=[\"train\", \"test\"],\n",
    "                    )\n",
    "    logging.info(\"Started Training\")\n",
    "    model_run.train_step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ag_news_classification_gru.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
