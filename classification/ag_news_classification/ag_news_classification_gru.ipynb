{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T17:35:22.330105Z",
     "start_time": "2021-10-06T17:35:18.228278Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guYzuv_Hdq0J",
    "outputId": "23575d1c-a254-47f2-cc0e-f1d59f4135f8"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.optim import Adam\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"running on gpu!!!\")\n",
    "else:\n",
    "    print(\"cpu :(\")\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "        print(\"running on colab\")\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        import sys\n",
    "        sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/ag_news\")\n",
    "\n",
    "from utils import ModelJob, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T17:36:02.852654Z",
     "start_time": "2021-10-06T17:36:02.779151Z"
    },
    "id": "3nw67DCUd04_"
   },
   "outputs": [],
   "source": [
    "class AgNewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, \n",
    "                vocab_size, min_frequency, \n",
    "                mode=\"train\", vocab=None):\n",
    "        super(AgNewsDataset).__init__()\n",
    "        logging.info(\"reading dataframe\")\n",
    "        self.df = df\n",
    "        self.nlp = spacy.load(name=\"en_core_web_sm\")\n",
    "        self.vocab_size = vocab_size\n",
    "        self.min_frequency = min_frequency\n",
    "        logging.info(f\"mode: {mode}\")\n",
    "        if mode == \"train\":\n",
    "            logging.info(\"preprocessing dataframe\")\n",
    "            self.preprocess_df()\n",
    "            logging.info(\"creating vocabulary\")\n",
    "            self.vocab = self.build_vocab()\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "            self.preprocess_df()\n",
    "            logging.info(\"preprocessing dataframe\")\n",
    "        logging.info(\"converting tokens to index\")\n",
    "        self.df[\"text_idx\"] = self.df[\"processed\"].apply(lambda ts: [self.vocab.get(t, self.vocab_size) \n",
    "                                                                                     for t in ts])\n",
    "        self.df[\"len\"] = self.df[\"text_idx\"].apply(len)\n",
    "    def preprocess_df(self):\n",
    "        self.df.columns = map(lambda x: x.lower(), self.df.columns)\n",
    "        self.df[\"text\"] = self.df[\"title\"] + \" \" + self.df[\"description\"]\n",
    "        self.df[\"text\"] = self.df[\"text\"].str.lower()\n",
    "        self.df[\"processed\"] = self.df[\"text\"].apply(self.preprocess)\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "        text = \" \".join(text.split())\n",
    "        doc = self.nlp(text, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\",\"ner\"])\n",
    "        lemmas = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        return lemmas\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        freq_dict = dict()\n",
    "        for index, row in self.df.iterrows():\n",
    "            for token in row[\"processed\"]:\n",
    "                freq_dict[token] = freq_dict.get(token, 0)+1\n",
    "        freq_dict = [(word, frequency) for word, frequency in freq_dict.items()\n",
    "                    if frequency >= self.min_frequency]\n",
    "        freq_dict = sorted(freq_dict, key = lambda x: x[1], reverse=True)\n",
    "        freq_dict = freq_dict[:self.vocab_size]\n",
    "        freq_dict = dict(freq_dict)\n",
    "        vocab = {token : idx+1 for idx, (token, _) in enumerate(freq_dict.items())}\n",
    "        return vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.iloc[idx][\"text_idx\"]\n",
    "        length = self.df.iloc[idx][\"len\"]\n",
    "        y = torch.tensor(self.df.iloc[idx][\"class index\"]-1)\n",
    "        return {\"X\": X,\n",
    "                \"lengths\": length,\n",
    "                \"y\": y}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X = [torch.tensor(row[\"X\"]) for row in batch]\n",
    "    lengths = [torch.tensor(row[\"lengths\"]) for row in batch]\n",
    "    y = [torch.tensor(row[\"y\"]) for row in batch]\n",
    "    X, y = pad_sequence(X, batch_first=True, padding_value=0), torch.tensor(y)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return X.to(device), lengths, y.to(device)\n",
    "    \n",
    "class NewsClassifierModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size,fc_units, num_classes):\n",
    "        super(NewsClassifierModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1,\n",
    "                                      embedding_dim=100, padding_idx=0)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim,\n",
    "                          hidden_size=hidden_size,\n",
    "                          bidirectional=True, \n",
    "                          batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(in_features=2*hidden_size, \n",
    "                           out_features=fc_units)\n",
    "        self.out = nn.Linear(in_features=fc_units,\n",
    "                            out_features=4)\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        (sequence, lengths) = x\n",
    "        mask = sequence!=0\n",
    "        emb = self.embedding(sequence)\n",
    "        emb_packed = pack_padded_sequence(emb, lengths=lengths, \n",
    "                                          batch_first=True, enforce_sorted=False)\n",
    "        output, h_t = self.rnn(emb_packed)\n",
    "        hidden_states = torch.cat((h_t[-2,:,:], h_t[-1, :, :]), dim=1)\n",
    "        hidden_states_dp = self.dropout(hidden_states)\n",
    "        fc_out = F.relu(self.fc(hidden_states_dp))\n",
    "        out = self.out(fc_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T17:54:29.972395Z",
     "start_time": "2021-10-06T17:36:03.581864Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVtHb2jbd4-e",
    "outputId": "ee26a454-f855-485a-b7e2-dbdcdd49c4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Read Dataframe\n",
      "INFO:root:Train Test Split\n",
      "INFO:root:Creating Datasets\n",
      "INFO:root:reading dataframe\n",
      "INFO:root:mode: train\n",
      "INFO:root:preprocessing dataframe\n",
      "INFO:root:creating vocabulary\n",
      "INFO:root:converting tokens to index\n",
      "INFO:root:reading dataframe\n",
      "INFO:root:mode: test\n",
      "INFO:root:preprocessing dataframe\n",
      "INFO:root:converting tokens to index\n",
      "INFO:root:Dataset lengths:: train: 37500, test: 12500\n",
      "INFO:root:Started Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.8360507488250732 : ACCURACY: 0.6593796014785767\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.5178371667861938 : ACCURACY: 0.828467071056366\n",
      "Best epoch : 1\n",
      "Saving model : ag_news_classification_gru.pth at models/\n",
      "EPOCH: 2 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.44534245133399963 : ACCURACY: 0.8403460383415222\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.41967785358428955 : ACCURACY: 0.8689606189727783\n",
      "Best epoch : 2\n",
      "Saving model : ag_news_classification_gru.pth at models/\n",
      "EPOCH: 3 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.3767261505126953 : ACCURACY: 0.8663148880004883\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.3977852165699005 : ACCURACY: 0.8764562010765076\n",
      "Best epoch : 3\n",
      "Saving model : ag_news_classification_gru.pth at models/\n",
      "EPOCH: 4 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.33937782049179077 : ACCURACY: 0.8793588280677795\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.3877856731414795 : ACCURACY: 0.8793652057647705\n",
      "Best epoch : 4\n",
      "Saving model : ag_news_classification_gru.pth at models/\n",
      "EPOCH: 5 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.30652323365211487 : ACCURACY: 0.8902024030685425\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.388897180557251 : ACCURACY: 0.880364179611206\n",
      "EPOCH: 6 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.2772863805294037 : ACCURACY: 0.9022932052612305\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.40973231196403503 : ACCURACY: 0.8777379989624023\n",
      "EPOCH: 7 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.243991881608963 : ACCURACY: 0.9129524230957031\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.4274342954158783 : ACCURACY: 0.8770891427993774\n",
      "EPOCH: 8 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.21532629430294037 : ACCURACY: 0.9229242205619812\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.4317801296710968 : ACCURACY: 0.8740738034248352\n",
      "EPOCH: 9 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.18434298038482666 : ACCURACY: 0.9348323941230774\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.453094482421875 : ACCURACY: 0.8763895630836487\n",
      "EPOCH: 10 out of 10\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 0.15011942386627197 : ACCURACY: 0.9457753300666809\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\tMODE: test : LOSS: 0.496621698141098 : ACCURACY: 0.8771904110908508\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        data_path = \"/content/drive/MyDrive/Colab Notebooks/ag_news\"\n",
    "        model_save_path = \"/content/drive/MyDrive/Colab Notebooks/ag_news\"\n",
    "        print(\"running on colab\")\n",
    "    else:\n",
    "        data_path = \"data/ag_news/\"\n",
    "        model_save_path = \"models/\"\n",
    "        print(\"running on local\")\n",
    "    df = pd.read_csv(os.path.join(data_path,\"train.csv\"))\n",
    "    df = df.sample(n=50000, random_state=9)\n",
    "    logging.info(\"Read Dataframe\")\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df_train, df_test = train_test_split(df, stratify=df[\"Class Index\"], random_state=9)\n",
    "    df_train.shape, df_test.shape\n",
    "    logging.info(\"Train Test Split\")\n",
    "    \n",
    "    logging.info(\"Creating Datasets\")\n",
    "    train_ds = AgNewsDataset(df=df_train,\n",
    "                    vocab_size=1000, \n",
    "                    min_frequency=25, \n",
    "                    mode=\"train\", vocab=None)\n",
    "    test_ds = AgNewsDataset(df=df_test,\n",
    "            vocab_size=1000, \n",
    "            min_frequency=25, \n",
    "            mode=\"test\", vocab=train_ds.vocab)\n",
    "    logging.info(f\"Dataset lengths:: train: {len(train_ds)}, test: {len(test_ds)}\")\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "    test_dl = DataLoader(test_ds, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    model = NewsClassifierModel(vocab_size=1000, \n",
    "                      embedding_dim=100, \n",
    "                      hidden_size=128,\n",
    "                      fc_units=256,\n",
    "                      num_classes=4\n",
    "                     )\n",
    "    model = model.to(device)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(params=model.parameters(), lr=0.001)\n",
    "    \n",
    "    model_run =  ModelJob(model=model,\n",
    "                    dataloaders = {\"train\": train_dl, \"test\":test_dl},\n",
    "                    model_save_path = model_save_path,\n",
    "                    model_save_name=\"ag_news_classification_gru.pth\",\n",
    "                    criterion=loss_func,\n",
    "                    optimizer=optimizer,\n",
    "                    n_epochs=10,\n",
    "                    phases=[\"train\", \"test\"],\n",
    "                    )\n",
    "    logging.info(\"Started Training\")\n",
    "    model_run.train_step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ag_news_classification_gru.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
