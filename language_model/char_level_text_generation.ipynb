{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:26:32.121779Z",
     "start_time": "2021-10-20T08:54:05.260891Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running on local\n",
      "INFO:root:Dataframe shapes: (3694, 1), (924, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu :(\n",
      "cpu :(\n",
      "EPOCH: 1 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 2.0143234729766846 : ACCURACY: 0.3481147289276123\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.7622320652008057 : ACCURACY: 0.4081234335899353\n",
      "Best epoch : 1\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 2 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.730285882949829 : ACCURACY: 0.4083976745605469\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.6741187572479248 : ACCURACY: 0.42755380272865295\n",
      "Best epoch : 2\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 3 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.6652040481567383 : ACCURACY: 0.42180824279785156\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.6366883516311646 : ACCURACY: 0.4350336492061615\n",
      "Best epoch : 3\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 4 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.628257155418396 : ACCURACY: 0.4302244186401367\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.6115983724594116 : ACCURACY: 0.44062280654907227\n",
      "Best epoch : 4\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 5 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.6025010347366333 : ACCURACY: 0.4354903995990753\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.596397042274475 : ACCURACY: 0.4438667595386505\n",
      "Best epoch : 5\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 6 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5841470956802368 : ACCURACY: 0.43959692120552063\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5849214792251587 : ACCURACY: 0.4468243420124054\n",
      "Best epoch : 6\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 7 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.568983793258667 : ACCURACY: 0.44292381405830383\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5758377313613892 : ACCURACY: 0.44888216257095337\n",
      "Best epoch : 7\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 8 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.558162808418274 : ACCURACY: 0.44550445675849915\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.568975567817688 : ACCURACY: 0.4502731263637543\n",
      "Best epoch : 8\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 9 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5485610961914062 : ACCURACY: 0.44744181632995605\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.561082124710083 : ACCURACY: 0.45196250081062317\n",
      "Best epoch : 9\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 10 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.540333867073059 : ACCURACY: 0.44962865114212036\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5584062337875366 : ACCURACY: 0.45219188928604126\n",
      "Best epoch : 10\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 11 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5335521697998047 : ACCURACY: 0.4509093463420868\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5516036748886108 : ACCURACY: 0.4542628824710846\n",
      "Best epoch : 11\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 12 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.527685523033142 : ACCURACY: 0.4526417851448059\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5485482215881348 : ACCURACY: 0.45481762290000916\n",
      "Best epoch : 12\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 13 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5227092504501343 : ACCURACY: 0.4537753164768219\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5452024936676025 : ACCURACY: 0.4562489986419678\n",
      "Best epoch : 13\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 14 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5172332525253296 : ACCURACY: 0.4552682042121887\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.542794108390808 : ACCURACY: 0.45667117834091187\n",
      "Best epoch : 14\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 15 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5134170055389404 : ACCURACY: 0.45616602897644043\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5395734310150146 : ACCURACY: 0.4578356444835663\n",
      "Best epoch : 15\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 16 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5096302032470703 : ACCURACY: 0.4571203887462616\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5375018119812012 : ACCURACY: 0.4576292335987091\n",
      "Best epoch : 16\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 17 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5061731338500977 : ACCURACY: 0.4579858183860779\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5355949401855469 : ACCURACY: 0.4585227966308594\n",
      "Best epoch : 17\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 18 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5039981603622437 : ACCURACY: 0.45830461382865906\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5334473848342896 : ACCURACY: 0.4585781693458557\n",
      "Best epoch : 18\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 19 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.5005320310592651 : ACCURACY: 0.4590640664100647\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5338000059127808 : ACCURACY: 0.45854252576828003\n",
      "EPOCH: 20 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4977655410766602 : ACCURACY: 0.459757924079895\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5304408073425293 : ACCURACY: 0.4593025743961334\n",
      "Best epoch : 20\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 21 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4959648847579956 : ACCURACY: 0.46030041575431824\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5283803939819336 : ACCURACY: 0.4603731036186218\n",
      "Best epoch : 21\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 22 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4935725927352905 : ACCURACY: 0.4609946310520172\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5277193784713745 : ACCURACY: 0.4603392481803894\n",
      "Best epoch : 22\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 23 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4917206764221191 : ACCURACY: 0.4614785611629486\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5270737409591675 : ACCURACY: 0.45973795652389526\n",
      "Best epoch : 23\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 24 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4900801181793213 : ACCURACY: 0.4619010090827942\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5263864994049072 : ACCURACY: 0.4609658718109131\n",
      "Best epoch : 24\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 25 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4886806011199951 : ACCURACY: 0.4620130658149719\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.525317668914795 : ACCURACY: 0.461016982793808\n",
      "Best epoch : 25\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 26 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4862384796142578 : ACCURACY: 0.4624650180339813\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5247310400009155 : ACCURACY: 0.4608898162841797\n",
      "Best epoch : 26\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 27 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4849578142166138 : ACCURACY: 0.46297016739845276\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5230129957199097 : ACCURACY: 0.4614158570766449\n",
      "Best epoch : 27\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 28 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4833682775497437 : ACCURACY: 0.46372395753860474\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5201339721679688 : ACCURACY: 0.46253055334091187\n",
      "Best epoch : 28\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 29 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4824904203414917 : ACCURACY: 0.46393871307373047\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5199990272521973 : ACCURACY: 0.4622558355331421\n",
      "Best epoch : 29\n",
      "Saving model : language_model_sp_gru.pth at models/\n",
      "EPOCH: 30 out of 30\n",
      "||||||||||||||||||||||||||||\n",
      "\tMODE: train : LOSS: 1.4806249141693115 : ACCURACY: 0.4643857181072235\n",
      "|||||||\n",
      "\tMODE: test : LOSS: 1.5209004878997803 : ACCURACY: 0.46185269951820374\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.optim import Adam\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"running on gpu!!!\")\n",
    "else:\n",
    "    print(\"cpu :(\")\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "        print(\"running on colab\")\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        import sys\n",
    "        sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/shakespeare\")\n",
    "\n",
    "from utils import ModelJob\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "\n",
    "class ShakespeareDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, seq_len, mode=None, vocab=None, vocab_ctoi=None):\n",
    "        self.df = df\n",
    "        self.seq_len = seq_len\n",
    "        self.mode = mode\n",
    "        self.df[\"name\"] = self.df[\"name\"].str.lower()\n",
    "        self.df['name'] = self.df[\"name\"].str.replace(\"\\n\", \" \")\n",
    "        self.df['name'] = self.df[\"name\"].str.replace(\"[^\\w+\\s]\", \"\")\n",
    "        #logging.info(\"Building vocabulary\")\n",
    "        if self.mode == \"train\":\n",
    "            self.vocab, self.vocab_ctoi = self.build_vocab()\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "            self.vocab_ctoi = vocab_ctoi\n",
    "        #logging.info(\"Creating indices\")\n",
    "        self.df[\"input_idx\"] = self.df[\"name\"].apply(lambda x: [self.vocab[t] for t in x if t in self.vocab.keys()])\n",
    "        self.vocab_size = len(self.vocab)+1\n",
    "        #logging.info(\"Creating sequences\")\n",
    "        if self.mode != \"predict\":\n",
    "            self.df[\"sequences\"] = self.df[\"input_idx\"].apply(self.create_sequence)\n",
    "            self.df_sequences = self.df.loc[:, [\"sequences\"]].explode(\"sequences\").reset_index(drop=True)\n",
    "            self.df_sequences[\"len\"] = self.df_sequences[\"sequences\"].apply(len)-1\n",
    "        else:\n",
    "            self.df_sequences = self.df\n",
    "            self.df_sequences.rename(columns = {\"input_idx\": \"sequences\"}, inplace=True)\n",
    "            self.df_sequences[\"len\"] = self.df_sequences[\"sequences\"].apply(len)\n",
    "        self.df_sequences = self.df_sequences.loc[self.df_sequences[\"len\"]>0]\n",
    "        \n",
    "    def create_sequence(self, row):\n",
    "        sequences = []\n",
    "        char_len = len(row)\n",
    "        for idx in range(char_len):\n",
    "            sequence = row[idx:idx+self.seq_len+1]\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        char_series = self.df[\"name\"].apply(lambda x: np.array(list(x)))\n",
    "        chars = np.unique(np.concatenate(char_series.values))\n",
    "        vocab = {char:idx+1 for idx, char in enumerate(chars)}\n",
    "        vocab_ctoi = {idx+1:char for idx, char in enumerate(chars)}\n",
    "        return vocab, vocab_ctoi\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df_sequences.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        df_batch = self.df_sequences.iloc[idx]\n",
    "        if self.mode!=\"predict\":\n",
    "            return {\"X\": df_batch[\"sequences\"][:-1],\n",
    "                    \"len\": df_batch[\"len\"],\n",
    "                    \"y\": df_batch[\"sequences\"][1:]}\n",
    "        else:\n",
    "            return torch.tensor(df_batch[\"sequences\"]).to(device),df_batch[\"len\"]\n",
    "\n",
    "def collate_fn(batch, mode):\n",
    "    X = [torch.tensor(row[\"X\"]) for row in batch]\n",
    "    lens = [row[\"len\"] for row in batch]\n",
    "    \n",
    "    if mode == \"predict\":\n",
    "        return X, lens\n",
    "    else:\n",
    "        padded_X = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "        y = [torch.tensor(row[\"y\"]) for row in batch]\n",
    "        padded_y = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "        return padded_X.to(device), lens, torch.tensor(padded_y).to(device).reshape(-1)\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, \n",
    "                hidden_size):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, \n",
    "                                     embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, \n",
    "                          hidden_size=hidden_size,\n",
    "                          bidirectional=False,\n",
    "                          batch_first=True\n",
    "                         )\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc_1 = nn.Linear(in_features=hidden_size,\n",
    "                             out_features=hidden_size//2)\n",
    "        self.fc = nn.Linear(in_features=hidden_size//2, \n",
    "                           out_features=self.vocab_size)\n",
    "    def forward(self, x, h_t_1=None, mode=\"train\"):\n",
    "        if len(x) == 2:\n",
    "            (seq, lens) = x\n",
    "        else:\n",
    "            (seq, lens, state) = x\n",
    "        emb = self.embedding(seq)\n",
    "        emb_packed = pack_padded_sequence(emb, lengths=lens, \n",
    "                                          batch_first=True,\n",
    "                                         enforce_sorted=False)\n",
    "        if h_t_1 is not None:\n",
    "            output, h_t = self.rnn(emb_packed, h_t_1)\n",
    "        else:\n",
    "            output, h_t = self.rnn(emb_packed)\n",
    "        output, out_lengths = pad_packed_sequence(output, batch_first=True)\n",
    "        output = self.dropout(output)\n",
    "        fc_out  = F.relu(self.fc_1(output.reshape(output.shape[0]*output.shape[1], -1)))\n",
    "        logits = self.fc(fc_out)\n",
    "        if mode != \"train\":\n",
    "            logits = logits.contiguous().view(output.shape[0], output.shape[1], -1)\n",
    "        return logits, h_t, out_lengths\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if \"COLAB_GPU\" in os.environ:\n",
    "        logging.info(\"Running on colab\")\n",
    "        data_path = \"/content/drive/MyDrive/Colab Notebooks/shakespeare/sonnet.txt\"\n",
    "        model_save_path = \"/content/drive/MyDrive/Colab Notebooks/shakespeare/models/\"\n",
    "    else:\n",
    "        logging.info(\"Running on local\")\n",
    "        data_path = \"data/shakespeare/sonnet.txt\"\n",
    "        model_save_path = \"models/\"\n",
    "    df = pd.read_table(data_path, header=None, names = [\"name\"])\n",
    "    df = df.sample(n=df.shape[0], random_state=9)\n",
    "    df_train = df.iloc[0: int(0.8*df.shape[0])]\n",
    "    df_test = df.iloc[int(0.8*df.shape[0]):]\n",
    "    logging.info(f\"Dataframe shapes: {df_train.shape}, {df_test.shape}\")\n",
    "    train_ds = ShakespeareDataset(df=df_train, seq_len=10, mode=\"train\")\n",
    "    test_ds = ShakespeareDataset(df=df_test, seq_len=10, mode=\"test\", \n",
    "                             vocab=train_ds.vocab, vocab_ctoi=train_ds.vocab_ctoi)\n",
    "\n",
    "train_dl = DataLoader(dataset=train_ds, \n",
    "                        batch_size=256,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=lambda x: collate_fn(x, mode=\"train\")\n",
    "                        )\n",
    "test_dl = DataLoader(dataset=test_ds, \n",
    "                     batch_size=256,\n",
    "                     shuffle=True,\n",
    "                     collate_fn=lambda x: collate_fn(x, mode=\"test\")\n",
    "                     )\n",
    "\n",
    "model = LanguageModel(vocab_size=train_ds.vocab_size,\n",
    "                     embedding_dim=100,\n",
    "                     hidden_size=128)\n",
    "model = model.to(device)\n",
    "                        \n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "model_run = ModelJob(model=model,\n",
    "                    dataloaders={\"train\":train_dl,\n",
    "                                 \"test\": test_dl},\n",
    "                    model_save_path=model_save_path,\n",
    "                    criterion=loss_func,\n",
    "                    optimizer=optimizer,\n",
    "                    n_epochs=30,\n",
    "                    phases=[\"train\",\"test\"],\n",
    "                    model_save_name=\"language_model_sp_gru.pth\")\n",
    "model_run.train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:26:33.818096Z",
     "start_time": "2021-10-20T09:26:32.124728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: time, generated: times foll rest sail features nights bear alleath thee\n",
      "seed: bless, generated: blessest restand that lays i perfumes eye thee than hat\n",
      "seed: think, generated: think do delight which i snot nor the selffied i have s\n",
      "seed: thou, generated: thou perpose wishd all that tis are diseasd from my lo\n",
      "seed: tender, generated: tender a true md against the thing more still are eyes u\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, seed_text,  seq_len, temperature):\n",
    "    model.eval()\n",
    "    for idx in range(seq_len):\n",
    "        df_text = pd.DataFrame([seed_text], columns=[\"name\"])\n",
    "\n",
    "        predict_ds = ShakespeareDataset(df=df_text, seq_len=10, \n",
    "                                    mode=\"predict\", \n",
    "                                    vocab=train_ds.vocab,\n",
    "                                   vocab_ctoi = train_ds.vocab_ctoi)\n",
    "        \n",
    "        predict_dl = DataLoader(dataset=predict_ds, \n",
    "                             batch_size=1,\n",
    "                             shuffle=True\n",
    "                             )\n",
    "        if idx == 0:\n",
    "            logits, state, out_lens = model_run.predict_step(predict_dl, if_y=False)\n",
    "        else:\n",
    "            logits, state, out_lens =  model_run.predict_step(predict_dl, h_t_1=state,  \n",
    "                                                    if_y=False, mode=\"predict\")\n",
    "        predicted_char_idx = torch.multinomial(F.softmax(logits[0, -1]/temperature), num_samples=1).item()\n",
    "        predicted_char = train_ds.vocab_ctoi[predicted_char_idx]\n",
    "        seed_text = seed_text+predicted_char\n",
    "    return seed_text\n",
    "\n",
    "for seed in [\"time\", \"bless\", \"think\", \"thou\", \"tender\"]:\n",
    "    generated_text  = generate_text(model = model_run.model, \n",
    "                                    seed_text=seed, seq_len=50, \n",
    "                                    temperature=0.9)\n",
    "    print(f\"seed: {seed}, generated: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
